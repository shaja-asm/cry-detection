{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaja-asm/cry-detection/blob/main/tf_lite_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgb5S3nbJXKL",
        "outputId": "72c162d3-ed2c-4d9e-d11e-4cf228eb0814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime\n",
        "\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YClY_ATkJXKP"
      },
      "outputs": [],
      "source": [
        "AUDIO_PATH = '/content/drive/MyDrive/CryCorpusFinal'\n",
        "CRY_FOLDER = os.path.join(AUDIO_PATH, 'cry')\n",
        "NOTCRY_FOLDER = os.path.join(AUDIO_PATH, 'notcry')\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H5QaLHaEJXKQ"
      },
      "outputs": [],
      "source": [
        "def load_audio_files(folder):\n",
        "    files = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith('.wav'):\n",
        "            files.append(os.path.join(folder, filename))\n",
        "    return files\n",
        "\n",
        "def normalize_audio(y):\n",
        "    return librosa.util.normalize(y)\n",
        "\n",
        "def compute_spectrogram(y, sr, n_fft=2048, hop_length=512):\n",
        "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "    D_dB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "    return D_dB\n",
        "\n",
        "def spectrogram_to_image(D_dB):\n",
        "    fig, ax = plt.subplots()\n",
        "    librosa.display.specshow(D_dB, sr=sr, hop_length=512, x_axis='time', y_axis='log', ax=ax)\n",
        "    ax.axis('off')\n",
        "    fig.canvas.draw()\n",
        "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "    img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "    plt.close(fig)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "upjbPHe6JXKR"
      },
      "outputs": [],
      "source": [
        "def save_spectrogram_to_disk(D_dB, save_path):\n",
        "    if not os.path.exists(os.path.dirname(save_path)):\n",
        "        os.makedirs(os.path.dirname(save_path))\n",
        "    np.save(save_path, D_dB)\n",
        "\n",
        "cry_files = load_audio_files(CRY_FOLDER)\n",
        "notcry_files = load_audio_files(NOTCRY_FOLDER)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for idx, file in enumerate(cry_files):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    y = normalize_audio(y)\n",
        "    D_dB = compute_spectrogram(y, sr)\n",
        "    save_path = os.path.join('spectrograms', f'cry_{idx}.npy')\n",
        "    save_spectrogram_to_disk(D_dB, save_path)\n",
        "    data.append(save_path)\n",
        "    labels.append(1)\n",
        "\n",
        "for idx, file in enumerate(notcry_files):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    y = normalize_audio(y)\n",
        "    D_dB = compute_spectrogram(y, sr)\n",
        "    save_path = os.path.join('spectrograms', f'notcry_{idx}.npy')\n",
        "    save_spectrogram_to_disk(D_dB, save_path)\n",
        "    data.append(save_path)\n",
        "    labels.append(0)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuPLsd8VJXKU",
        "outputId": "46d3f01e-2c37-4931-cc41-cfddc6670937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 175ms/step - accuracy: 0.5016 - loss: 9.9555 - val_accuracy: 0.5270 - val_loss: 0.6930\n",
            "Epoch 2/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.5178 - loss: 0.6928 - val_accuracy: 0.5245 - val_loss: 0.6928\n",
            "Epoch 3/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5383 - loss: 0.6917 - val_accuracy: 0.5245 - val_loss: 0.6922\n",
            "Epoch 4/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.5271 - loss: 0.6871 - val_accuracy: 0.5270 - val_loss: 0.6927\n",
            "Epoch 5/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.5439 - loss: 0.6733 - val_accuracy: 0.4755 - val_loss: 0.6543\n",
            "Epoch 6/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6162 - loss: 0.6100 - val_accuracy: 0.4853 - val_loss: 0.6842\n",
            "Epoch 7/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7002 - loss: 0.5024 - val_accuracy: 0.5294 - val_loss: 0.6395\n",
            "Epoch 8/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.7036 - loss: 0.4831 - val_accuracy: 0.6446 - val_loss: 0.5846\n",
            "Epoch 9/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.6872 - loss: 0.4972 - val_accuracy: 0.6250 - val_loss: 0.5795\n",
            "Epoch 10/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6929 - loss: 0.4962 - val_accuracy: 0.7525 - val_loss: 0.5117\n",
            "Epoch 11/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - accuracy: 0.6783 - loss: 0.4790 - val_accuracy: 0.7328 - val_loss: 0.5286\n",
            "Epoch 12/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6610 - loss: 0.5163 - val_accuracy: 0.6520 - val_loss: 0.5760\n",
            "Epoch 13/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - accuracy: 0.7045 - loss: 0.4653 - val_accuracy: 0.6716 - val_loss: 0.5684\n",
            "Epoch 14/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - accuracy: 0.7375 - loss: 0.4419 - val_accuracy: 0.5637 - val_loss: 0.6532\n",
            "Epoch 15/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.7159 - loss: 0.4601 - val_accuracy: 0.8137 - val_loss: 0.4340\n",
            "Epoch 16/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.6695 - loss: 0.4746 - val_accuracy: 0.6985 - val_loss: 0.5449\n",
            "Epoch 17/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7208 - loss: 0.4382 - val_accuracy: 0.7623 - val_loss: 0.4906\n",
            "Epoch 18/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6993 - loss: 0.4614 - val_accuracy: 0.7990 - val_loss: 0.4848\n",
            "Epoch 19/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.6912 - loss: 0.4949 - val_accuracy: 0.8211 - val_loss: 0.4307\n",
            "Epoch 20/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7092 - loss: 0.4595 - val_accuracy: 0.7794 - val_loss: 0.4561\n",
            "Epoch 21/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.7146 - loss: 0.4306 - val_accuracy: 0.7402 - val_loss: 0.4714\n",
            "Epoch 22/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.7160 - loss: 0.4496 - val_accuracy: 0.7279 - val_loss: 0.4881\n",
            "Epoch 23/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7287 - loss: 0.4494 - val_accuracy: 0.9044 - val_loss: 0.4063\n",
            "Epoch 24/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.6970 - loss: 0.4578 - val_accuracy: 0.8015 - val_loss: 0.4116\n",
            "Epoch 25/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.7229 - loss: 0.4556 - val_accuracy: 0.8946 - val_loss: 0.4026\n",
            "Training complete. Best model saved as 'cry_detection_best_model.keras'\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom data generator\n",
        "class OnTheFlyDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, file_paths, labels, batch_size, img_size, shuffle=True):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.file_paths))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_file_paths = [self.file_paths[i] for i in batch_indices]\n",
        "        batch_labels = [self.labels[i] for i in batch_indices]\n",
        "\n",
        "        X, y = self.__data_generation(batch_file_paths, batch_labels)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __data_generation(self, batch_file_paths, batch_labels):\n",
        "        X = np.empty((len(batch_file_paths), *self.img_size, 1), dtype=np.float32)\n",
        "        y = np.empty((len(batch_file_paths),), dtype=int)\n",
        "\n",
        "        for i, file_path in enumerate(batch_file_paths):\n",
        "            D_dB = np.load(file_path)\n",
        "            D_dB = D_dB[..., np.newaxis]  # Add channel dimension\n",
        "            D_dB = tf.image.resize(D_dB, self.img_size).numpy()\n",
        "            X[i,] = D_dB\n",
        "            y[i] = batch_labels[i]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "train_generator = OnTheFlyDataGenerator(X_train, y_train, BATCH_SIZE, IMG_SIZE, shuffle=True)\n",
        "val_generator = OnTheFlyDataGenerator(X_val, y_val, BATCH_SIZE, IMG_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch='500,520')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=tensorboard_callback\n",
        "    )\n",
        "\n",
        "# Clear session\n",
        "# tf.keras.backend.clear_session()\n",
        "\n",
        "# Save the best model\n",
        "model.save('cry_detection_best_model.keras')\n",
        "\n",
        "print(\"Training complete. Best model saved as 'cry_detection_best_model.keras'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gZHWYittJXK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186eb5c3-121c-42fc-e473-41b8339d7589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step\n",
            "Accuracy: 0.8946078431372549\n",
            "F1 Score: 0.8948655256723717\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(val_generator)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "print(f'Accuracy: {acc}')\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "model.save('cry_detection_best_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qnk1eayLJXK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0821f336-2cbe-4439-b9e0-e52aef671f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpte066mci'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='keras_tensor_11')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132493970588944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132495857666352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132495857666880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132495857558704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132493962944480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132493962946240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132493962942192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132493962948528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model converted to TensorFlow Lite and saved.\n"
          ]
        }
      ],
      "source": [
        "# Convert to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('cry_detection_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print('Model converted to TensorFlow Lite and saved.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}