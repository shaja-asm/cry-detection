{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaja-asm/cry-detection/blob/main/tf_lite_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgb5S3nbJXKL",
        "outputId": "3d54d4d1-9e96-4d9b-dadf-0fa031c8e54d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#     try:\n",
        "#         for gpu in gpus:\n",
        "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
        "#     except RuntimeError as e:\n",
        "#         print(e)\n",
        "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YClY_ATkJXKP"
      },
      "outputs": [],
      "source": [
        "AUDIO_PATH = 'CryCorpusFinal'\n",
        "CRY_FOLDER = os.path.join(AUDIO_PATH, 'cry')\n",
        "NOTCRY_FOLDER = os.path.join(AUDIO_PATH, 'notcry')\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5QaLHaEJXKQ"
      },
      "outputs": [],
      "source": [
        "def load_audio_files(folder):\n",
        "    files = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith('.wav'):\n",
        "            files.append(os.path.join(folder, filename))\n",
        "    return files\n",
        "\n",
        "def compute_spectrogram(y, sr, n_fft=2048, hop_length=512):\n",
        "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "    D_dB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "    return D_dB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upjbPHe6JXKR"
      },
      "outputs": [],
      "source": [
        "def save_spectrogram_to_disk(D_dB, save_path):\n",
        "    if not os.path.exists(os.path.dirname(save_path)):\n",
        "        os.makedirs(os.path.dirname(save_path))\n",
        "    np.save(save_path, D_dB)\n",
        "\n",
        "cry_files = load_audio_files(CRY_FOLDER)\n",
        "notcry_files = load_audio_files(NOTCRY_FOLDER)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for idx, file in enumerate(cry_files):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    y = librosa.util.normalize(y)\n",
        "    D_dB = compute_spectrogram(y, sr)\n",
        "    save_path = os.path.join(f'{0}/spectrograms'.format(AUDIO_PATH), f'cry_{idx}.npy')\n",
        "    save_spectrogram_to_disk(D_dB, save_path)\n",
        "    data.append(save_path)\n",
        "    labels.append(1)\n",
        "\n",
        "for idx, file in enumerate(notcry_files):\n",
        "    y, sr = librosa.load(file, sr=None)\n",
        "    y = librosa.util.normalize(y)\n",
        "    D_dB = compute_spectrogram(y, sr)\n",
        "    save_path = os.path.join(f'{0}/spectrograms'.format(AUDIO_PATH), f'notcry_{idx}.npy')\n",
        "    save_spectrogram_to_disk(D_dB, save_path)\n",
        "    data.append(save_path)\n",
        "    labels.append(0)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuPLsd8VJXKU",
        "outputId": "069a5f50-4a6e-4bea-c36f-72c04e5de8de"
      },
      "outputs": [],
      "source": [
        "# Split the datasets\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "class OnTheFlyDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, file_paths, labels, batch_size, img_size, shuffle=True, augment=False):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indices = np.arange(len(self.file_paths))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_file_paths = [self.file_paths[i] for i in batch_indices]\n",
        "        batch_labels = [self.labels[i] for i in batch_indices]\n",
        "\n",
        "        X, y = self.__data_generation(batch_file_paths, batch_labels)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __data_generation(self, batch_file_paths, batch_labels):\n",
        "        X = np.empty((len(batch_file_paths), *self.img_size, 1), dtype=np.float32)\n",
        "        y = np.empty((len(batch_file_paths),), dtype=int)\n",
        "\n",
        "        for i, file_path in enumerate(batch_file_paths):\n",
        "            D_dB = np.load(file_path)\n",
        "            D_dB = D_dB[..., np.newaxis]  # Add channel dimension\n",
        "            D_dB = tf.image.resize(D_dB, self.img_size).numpy()\n",
        "            if self.augment:\n",
        "                D_dB = tf.image.random_flip_left_right(D_dB)\n",
        "                D_dB = tf.image.random_flip_up_down(D_dB)\n",
        "                D_dB = tf.image.random_brightness(D_dB, max_delta=0.2)\n",
        "            X[i,] = D_dB\n",
        "            y[i] = batch_labels[i]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "# Augment training data\n",
        "train_generator = OnTheFlyDataGenerator(X_train, y_train, BATCH_SIZE, IMG_SIZE, shuffle=True, augment=True)\n",
        "val_generator = OnTheFlyDataGenerator(X_val, y_val, BATCH_SIZE, IMG_SIZE, shuffle=False, augment=False)\n",
        "\n",
        "# Define the model with batch normalization and l2 regularization\n",
        "l2_regularizer = tf.keras.regularizers.l2(0.001)\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1), kernel_regularizer=l2_regularizer),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2_regularizer),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2_regularizer),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2_regularizer),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch='500,520')\n",
        "\n",
        "# Save the best model during training\n",
        "checkpoint_callback = ModelCheckpoint('cry_detection_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Train the model with the added callbacks\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[tensorboard_callback, checkpoint_callback, lr_callback]\n",
        "    )\n",
        "\n",
        "print(\"Training complete. Model saved as 'cry_detection_model.keras'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZHWYittJXK5",
        "outputId": "234ee77d-c9fc-4c62-e6cf-024b88c5853f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step\n",
            "Accuracy: 0.9215686274509803\n",
            "F1 Score: 0.9111111111111111\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(val_generator)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "print(f'Accuracy: {acc}')\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "model.save('cry_detection_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnk1eayLJXK6",
        "outputId": "57875de9-a024-4d82-f68e-bae37370559b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp460j4yag/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp460j4yag/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmp460j4yag'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='keras_tensor_17')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140275275206848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275211072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275207728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275213360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275209840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275211600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275215472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275217760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275207024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275218288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275212480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275216704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275216176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274663712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274663360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274666352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274661952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274664064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274664944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274670752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274665120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274672688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1723022124.594840   79590 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
            "W0000 00:00:1723022124.594905   79590 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
            "2024-08-07 14:45:24.595165: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp460j4yag\n",
            "2024-08-07 14:45:24.596989: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2024-08-07 14:45:24.597017: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp460j4yag\n",
            "2024-08-07 14:45:24.614182: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2024-08-07 14:45:24.714847: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp460j4yag\n",
            "2024-08-07 14:45:24.742380: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 147219 microseconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpkbv26fua/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpkbv26fua/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpkbv26fua'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='keras_tensor_17')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140275275206848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275211072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275207728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275213360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275209840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275211600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275215472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275217760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275207024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275218288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275212480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275216704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275275216176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274663712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274663360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274666352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274661952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274664064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274664944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274670752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274665120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140275274672688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1723022126.716757   79590 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
            "W0000 00:00:1723022126.716838   79590 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
            "2024-08-07 14:45:26.717112: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkbv26fua\n",
            "2024-08-07 14:45:26.721117: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2024-08-07 14:45:26.721158: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpkbv26fua\n",
            "2024-08-07 14:45:26.745270: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2024-08-07 14:45:26.886137: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpkbv26fua\n",
            "2024-08-07 14:45:26.927222: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 210114 microseconds.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1374136"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pathlib\n",
        "tflite_models_dir = pathlib.Path(\"tflite_models\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = tflite_models_dir/\"cry_detection_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_fp16_model = converter.convert()\n",
        "tflite_model_fp16_file = tflite_models_dir/\"cry_detection_model_quant_f16.tflite\"\n",
        "tflite_model_fp16_file.write_bytes(tflite_fp16_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: P19_195_cry.wav, Prediction: Not Cry\n",
            "File: P19_607_notcry.wav, Prediction: Not Cry\n",
            "File: P19_630_cry.wav, Prediction: Not Cry\n",
            "File: P19_365_cry.wav, Prediction: Cry\n",
            "File: P26_824_cry.wav, Prediction: Cry\n",
            "File: P36_411_notcry.wav, Prediction: Not Cry\n",
            "File: P19_516_cry.wav, Prediction: Cry\n",
            "File: P19_45_notcry.wav, Prediction: Not Cry\n",
            "File: P19_476_cry.wav, Prediction: Cry\n",
            "File: P19_801_cry.wav, Prediction: Not Cry\n",
            "File: P19_426_cry.wav, Prediction: Cry\n",
            "File: P19_291_cry.wav, Prediction: Cry\n",
            "File: P15_3463_cry.wav, Prediction: Cry\n",
            "File: P15_3571_cry.wav, Prediction: Cry\n",
            "File: P19_215_cry.wav, Prediction: Cry\n",
            "File: P19_849_cry.wav, Prediction: Not Cry\n",
            "File: P19_465_cry.wav, Prediction: Cry\n",
            "File: P17_46_cry.wav, Prediction: Cry\n",
            "File: P19_915_cry.wav, Prediction: Not Cry\n",
            "File: P19_24_cry.wav, Prediction: Cry\n",
            "File: P36_54_notcry.wav, Prediction: Not Cry\n",
            "File: P15_3513_cry.wav, Prediction: Cry\n",
            "File: P17_744_cry.wav, Prediction: Cry\n",
            "File: P19_546_cry.wav, Prediction: Cry\n",
            "File: P19_196_cry.wav, Prediction: Not Cry\n",
            "File: P19_163_cry.wav, Prediction: Cry\n",
            "File: P19_502_cry.wav, Prediction: Cry\n",
            "File: P19_635_notcry.wav, Prediction: Not Cry\n",
            "File: P19_689_cry.wav, Prediction: Not Cry\n",
            "File: P36_191_notcry.wav, Prediction: Not Cry\n",
            "File: P19_199_cry.wav, Prediction: Not Cry\n",
            "File: P19_629_notcry.wav, Prediction: Not Cry\n",
            "File: P19_491_cry.wav, Prediction: Cry\n",
            "File: P26_820_cry.wav, Prediction: Cry\n",
            "File: P19_507_cry.wav, Prediction: Not Cry\n",
            "File: P36_181_notcry.wav, Prediction: Not Cry\n",
            "File: P19_794_cry.wav, Prediction: Cry\n",
            "File: P19_42_notcry.wav, Prediction: Not Cry\n",
            "File: P36_466_notcry.wav, Prediction: Cry\n",
            "File: P19_481_cry.wav, Prediction: Cry\n",
            "File: P19_281_notcry.wav, Prediction: Not Cry\n",
            "File: P19_976_notcry.wav, Prediction: Not Cry\n",
            "File: P19_599_notcry.wav, Prediction: Not Cry\n",
            "File: P19_392_cry.wav, Prediction: Not Cry\n",
            "File: P19_545_cry.wav, Prediction: Cry\n",
            "File: P19_180_cry.wav, Prediction: Not Cry\n",
            "File: P36_472_notcry.wav, Prediction: Not Cry\n",
            "File: P36_14_notcry.wav, Prediction: Not Cry\n",
            "File: P36_30_notcry.wav, Prediction: Not Cry\n",
            "File: P19_743_cry.wav, Prediction: Cry\n",
            "File: P19_626_notcry.wav, Prediction: Not Cry\n",
            "File: P36_251_notcry.wav, Prediction: Not Cry\n",
            "File: P19_1016_notcry.wav, Prediction: Cry\n",
            "File: P19_489_cry.wav, Prediction: Cry\n",
            "File: P19_768_cry.wav, Prediction: Cry\n",
            "File: P19_557_cry.wav, Prediction: Cry\n",
            "File: P26_9_cry.wav, Prediction: Not Cry\n",
            "File: P19_662_notcry.wav, Prediction: Not Cry\n",
            "File: P19_886_cry.wav, Prediction: Cry\n",
            "File: P36_175_notcry.wav, Prediction: Not Cry\n",
            "File: P19_648_notcry.wav, Prediction: Not Cry\n",
            "File: P19_568_cry.wav, Prediction: Cry\n",
            "File: P19_16_notcry.wav, Prediction: Not Cry\n",
            "File: P19_724_cry.wav, Prediction: Not Cry\n",
            "File: P19_27_notcry.wav, Prediction: Not Cry\n",
            "File: P36_16_notcry.wav, Prediction: Not Cry\n",
            "File: P19_656_notcry.wav, Prediction: Not Cry\n",
            "File: P19_730_cry.wav, Prediction: Cry\n",
            "File: P19_167_cry.wav, Prediction: Cry\n",
            "File: P19_650_notcry.wav, Prediction: Not Cry\n",
            "File: P36_415_notcry.wav, Prediction: Not Cry\n",
            "File: P36_7_notcry.wav, Prediction: Not Cry\n",
            "File: P19_1038_notcry.wav, Prediction: Not Cry\n",
            "File: P36_285_notcry.wav, Prediction: Not Cry\n",
            "File: P17_43_cry.wav, Prediction: Not Cry\n",
            "File: P26_826_cry.wav, Prediction: Cry\n",
            "File: P17_2_notcry.wav, Prediction: Not Cry\n",
            "File: P19_405_cry.wav, Prediction: Cry\n",
            "File: P19_748_cry.wav, Prediction: Not Cry\n",
            "File: P36_52_notcry.wav, Prediction: Not Cry\n",
            "File: P15_3886_cry.wav, Prediction: Cry\n",
            "File: P19_661_notcry.wav, Prediction: Not Cry\n",
            "File: P19_653_notcry.wav, Prediction: Not Cry\n",
            "File: P19_994_notcry.wav, Prediction: Not Cry\n",
            "File: P19_415_cry.wav, Prediction: Not Cry\n",
            "File: P15_3686_cry.wav, Prediction: Cry\n",
            "File: P19_612_notcry.wav, Prediction: Not Cry\n",
            "File: P36_139_notcry.wav, Prediction: Not Cry\n",
            "File: P19_388_notcry.wav, Prediction: Not Cry\n",
            "File: P26_6_cry.wav, Prediction: Not Cry\n",
            "File: P19_798_cry.wav, Prediction: Cry\n",
            "File: P19_400_cry.wav, Prediction: Cry\n",
            "File: P19_504_cry.wav, Prediction: Cry\n",
            "File: P19_162_cry.wav, Prediction: Cry\n",
            "File: P19_800_cry.wav, Prediction: Not Cry\n",
            "File: P19_835_cry.wav, Prediction: Cry\n",
            "File: P19_179_cry.wav, Prediction: Not Cry\n",
            "File: P19_641_cry.wav, Prediction: Not Cry\n",
            "File: P36_252_notcry.wav, Prediction: Not Cry\n",
            "File: P19_434_notcry.wav, Prediction: Not Cry\n",
            "File: P19_39_notcry.wav, Prediction: Not Cry\n",
            "File: P19_760_cry.wav, Prediction: Cry\n",
            "File: P15_3743_cry.wav, Prediction: Cry\n",
            "File: P19_402_cry.wav, Prediction: Cry\n",
            "File: P19_847_cry.wav, Prediction: Not Cry\n",
            "File: P19_477_cry.wav, Prediction: Not Cry\n",
            "File: P19_369_cry.wav, Prediction: Cry\n",
            "File: P19_384_cry.wav, Prediction: Cry\n",
            "File: P19_646_notcry.wav, Prediction: Not Cry\n",
            "File: P36_179_notcry.wav, Prediction: Cry\n",
            "File: P36_12_notcry.wav, Prediction: Not Cry\n",
            "File: P19_514_cry.wav, Prediction: Cry\n",
            "File: P26_10_cry.wav, Prediction: Cry\n",
            "File: P17_20_notcry.wav, Prediction: Not Cry\n",
            "File: P19_888_cry.wav, Prediction: Cry\n",
            "File: P19_1027_notcry.wav, Prediction: Not Cry\n",
            "File: P19_223_cry.wav, Prediction: Not Cry\n",
            "File: P36_363_notcry.wav, Prediction: Not Cry\n",
            "File: P19_908_notcry.wav, Prediction: Not Cry\n",
            "File: P19_666_notcry.wav, Prediction: Not Cry\n",
            "File: P19_883_cry.wav, Prediction: Not Cry\n",
            "File: P19_31_notcry.wav, Prediction: Not Cry\n",
            "File: P17_975_cry.wav, Prediction: Cry\n",
            "File: P19_856_notcry.wav, Prediction: Not Cry\n",
            "File: P19_480_cry.wav, Prediction: Not Cry\n",
            "File: P19_398_cry.wav, Prediction: Cry\n",
            "File: P19_478_cry.wav, Prediction: Cry\n",
            "File: P15_3548_cry.wav, Prediction: Cry\n",
            "File: P19_499_cry.wav, Prediction: Cry\n",
            "File: P19_693_cry.wav, Prediction: Not Cry\n",
            "File: P19_473_cry.wav, Prediction: Cry\n",
            "File: P19_603_notcry.wav, Prediction: Not Cry\n",
            "File: P19_19_notcry.wav, Prediction: Not Cry\n",
            "File: P19_923_notcry.wav, Prediction: Cry\n",
            "File: P26_11_cry.wav, Prediction: Cry\n",
            "File: P19_38_notcry.wav, Prediction: Not Cry\n",
            "File: P19_556_cry.wav, Prediction: Cry\n",
            "File: P19_762_cry.wav, Prediction: Not Cry\n",
            "File: P36_6_notcry.wav, Prediction: Not Cry\n",
            "File: P19_574_cry.wav, Prediction: Not Cry\n",
            "File: P26_227_cry.wav, Prediction: Cry\n",
            "File: P15_3062_cry.wav, Prediction: Cry\n",
            "File: P36_4_notcry.wav, Prediction: Not Cry\n",
            "File: P19_848_cry.wav, Prediction: Not Cry\n",
            "File: P19_890_notcry.wav, Prediction: Not Cry\n",
            "File: P19_395_cry.wav, Prediction: Not Cry\n",
            "File: P19_577_cry.wav, Prediction: Cry\n",
            "File: P19_43_notcry.wav, Prediction: Not Cry\n",
            "File: P36_201_notcry.wav, Prediction: Not Cry\n",
            "File: P19_460_cry.wav, Prediction: Cry\n",
            "File: P19_37_notcry.wav, Prediction: Not Cry\n",
            "File: P19_812_cry.wav, Prediction: Not Cry\n",
            "File: P19_740_cry.wav, Prediction: Cry\n",
            "File: P19_620_notcry.wav, Prediction: Not Cry\n",
            "File: P36_174_notcry.wav, Prediction: Not Cry\n",
            "File: P19_539_cry.wav, Prediction: Not Cry\n",
            "File: P19_462_cry.wav, Prediction: Cry\n",
            "File: P19_614_notcry.wav, Prediction: Not Cry\n",
            "File: P26_221_cry.wav, Prediction: Cry\n",
            "File: P19_519_cry.wav, Prediction: Not Cry\n",
            "File: P19_654_notcry.wav, Prediction: Not Cry\n",
            "File: P19_591_notcry.wav, Prediction: Not Cry\n",
            "File: P17_41_cry.wav, Prediction: Not Cry\n",
            "File: P36_286_notcry.wav, Prediction: Not Cry\n",
            "File: P19_428_cry.wav, Prediction: Cry\n",
            "File: P26_223_cry.wav, Prediction: Cry\n",
            "File: P19_520_cry.wav, Prediction: Cry\n",
            "File: P19_810_cry.wav, Prediction: Not Cry\n",
            "File: P19_282_notcry.wav, Prediction: Cry\n",
            "File: P19_1041_cry.wav, Prediction: Not Cry\n",
            "File: P19_846_cry.wav, Prediction: Cry\n",
            "File: P19_627_notcry.wav, Prediction: Not Cry\n",
            "File: P19_840_cry.wav, Prediction: Cry\n",
            "File: P36_192_notcry.wav, Prediction: Not Cry\n",
            "File: P19_843_cry.wav, Prediction: Cry\n",
            "File: P19_606_notcry.wav, Prediction: Not Cry\n",
            "File: P19_393_cry.wav, Prediction: Not Cry\n",
            "File: P19_1028_notcry.wav, Prediction: Not Cry\n",
            "File: P19_734_cry.wav, Prediction: Cry\n",
            "File: P17_5_notcry.wav, Prediction: Not Cry\n",
            "File: P19_598_notcry.wav, Prediction: Not Cry\n",
            "File: P19_869_notcry.wav, Prediction: Not Cry\n",
            "File: P15_3484_cry.wav, Prediction: Cry\n",
            "File: P19_593_notcry.wav, Prediction: Not Cry\n",
            "File: P36_173_notcry.wav, Prediction: Not Cry\n",
            "File: P19_611_notcry.wav, Prediction: Not Cry\n",
            "File: P19_414_cry.wav, Prediction: Not Cry\n",
            "File: P19_604_notcry.wav, Prediction: Not Cry\n",
            "File: P19_417_cry.wav, Prediction: Cry\n",
            "File: P19_440_cry.wav, Prediction: Not Cry\n",
            "File: P19_643_notcry.wav, Prediction: Not Cry\n",
            "File: P19_837_cry.wav, Prediction: Cry\n",
            "File: P19_725_cry.wav, Prediction: Not Cry\n",
            "File: P19_283_notcry.wav, Prediction: Not Cry\n",
            "File: P19_550_cry.wav, Prediction: Cry\n",
            "File: P19_623_notcry.wav, Prediction: Not Cry\n",
            "File: P26_822_cry.wav, Prediction: Cry\n",
            "File: P19_170_cry.wav, Prediction: Not Cry\n",
            "File: P26_4_cry.wav, Prediction: Not Cry\n",
            "File: P19_389_notcry.wav, Prediction: Not Cry\n",
            "File: P26_823_cry.wav, Prediction: Cry\n",
            "File: P19_754_cry.wav, Prediction: Not Cry\n",
            "File: P36_371_notcry.wav, Prediction: Not Cry\n",
            "File: P19_296_notcry.wav, Prediction: Not Cry\n",
            "File: P26_829_cry.wav, Prediction: Cry\n",
            "File: P19_35_notcry.wav, Prediction: Not Cry\n",
            "File: P19_770_cry.wav, Prediction: Not Cry\n",
            "File: P19_691_cry.wav, Prediction: Not Cry\n",
            "File: P19_325_cry.wav, Prediction: Not Cry\n",
            "File: P26_226_cry.wav, Prediction: Cry\n",
            "File: P19_41_notcry.wav, Prediction: Not Cry\n",
            "File: P19_622_notcry.wav, Prediction: Not Cry\n",
            "File: P19_917_cry.wav, Prediction: Cry\n",
            "File: P26_7_cry.wav, Prediction: Not Cry\n",
            "File: P36_210_notcry.wav, Prediction: Not Cry\n",
            "File: P19_815_cry.wav, Prediction: Not Cry\n",
            "File: P19_833_notcry.wav, Prediction: Not Cry\n",
            "File: P19_645_notcry.wav, Prediction: Not Cry\n",
            "File: P19_897_notcry.wav, Prediction: Not Cry\n",
            "File: P15_3476_cry.wav, Prediction: Cry\n",
            "File: P36_178_notcry.wav, Prediction: Not Cry\n",
            "File: P19_28_notcry.wav, Prediction: Not Cry\n",
            "File: P15_3134_cry.wav, Prediction: Cry\n",
            "File: P26_225_cry.wav, Prediction: Cry\n",
            "File: P19_879_cry.wav, Prediction: Cry\n",
            "Prediction Accuracy: 76.44%\n"
          ]
        }
      ],
      "source": [
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"tflite_models/cry_detection_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Function to preprocess the audio file and convert it to a spectrogram\n",
        "def preprocess_audio(file_path, img_size):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    y = librosa.util.normalize(y)\n",
        "    D = librosa.stft(y, n_fft=2048, hop_length=512)\n",
        "    D_dB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "    D_dB_resized = tf.image.resize(D_dB[..., np.newaxis], img_size).numpy()\n",
        "    return D_dB_resized\n",
        "\n",
        "def predict(file_path, img_size=(32, 32)):\n",
        "    # Preprocess the audio file\n",
        "    input_data = preprocess_audio(file_path, img_size)\n",
        "    \n",
        "    # Add batch dimension\n",
        "    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
        "    \n",
        "    # Set the tensor to point to the input data to be inferred\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    \n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "    \n",
        "    # Extract output data\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    \n",
        "    return output_data\n",
        "\n",
        "# Function to process all .wav files in a folder and calculate prediction accuracy\n",
        "def process_folder(folder_path, img_size=(64, 64)):\n",
        "    correct_predictions = 0\n",
        "    total_files = 0\n",
        "    results = []\n",
        "    \n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.wav'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            prediction = predict(file_path, img_size)\n",
        "            prediction_label = 'Cry' if prediction > 0.5 else 'Not Cry'\n",
        "            results.append((file_name, prediction_label))\n",
        "            \n",
        "            # Determine ground truth from the file name\n",
        "            ground_truth = 'Cry' if '_cry.wav' in file_name else 'Not Cry'\n",
        "            \n",
        "            if prediction_label == ground_truth:\n",
        "                correct_predictions += 1\n",
        "            \n",
        "            total_files += 1\n",
        "\n",
        "    # Calculate prediction accuracy\n",
        "    accuracy = (correct_predictions / total_files) * 100 if total_files > 0 else 0\n",
        "    \n",
        "    return results, accuracy\n",
        "\n",
        "# Example usage\n",
        "folder_path = 'CryCorpusFinal/Test'  # Replace with the path to your folder containing .wav files\n",
        "predictions, accuracy = process_folder(folder_path)\n",
        "\n",
        "for file_name, prediction_label in predictions:\n",
        "    print(f\"File: {file_name}, Prediction: {prediction_label}\")\n",
        "\n",
        "print(f\"Prediction Accuracy: {accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
