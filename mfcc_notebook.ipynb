{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scipy.ndimage import zoom\n",
    "import ctypes\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Set GPU configuration (if applicable)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') \n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_PATH = '/home/garfield/CryCorpusFinal'\n",
    "CRY_FOLDER = os.path.join(AUDIO_PATH, 'cry_augmented')\n",
    "NOTCRY_FOLDER = os.path.join(AUDIO_PATH, 'notcry_augmented')\n",
    "NUM_MFCC = 33  #  Number of MFCC coefficients to extract\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "MODEL = 'cnn'  # Choice: 'cnn' or 'lstm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.fftpack\n",
    "\n",
    "def load_audio_files(folder):\n",
    "    files = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            files.append(os.path.join(folder, filename))\n",
    "    return files\n",
    "\n",
    "def compute_mfcc(y, sr, n_mfcc=NUM_MFCC):\n",
    "    # Pre-emphasis filter\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_signal = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
    "    \n",
    "    # Frame parameters\n",
    "    frame_size = 0.025  # 25 ms\n",
    "    frame_stride = 0.010  # 10 ms\n",
    "    frame_length, frame_step = int(round(frame_size * sr)), int(round(frame_stride * sr))\n",
    "    signal_length = len(emphasized_signal)\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))\n",
    "    \n",
    "    # Padding\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(emphasized_signal, z)\n",
    "    \n",
    "    # Framing\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    # Windowing with Hamming window\n",
    "    frames *= np.hamming(frame_length)\n",
    "    \n",
    "    # Fourier Transform and Power Spectrum\n",
    "    NFFT = 512\n",
    "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude spectrum\n",
    "    pow_frames = ((1.0 / NFFT) * (mag_frames ** 2))  # Power spectrum\n",
    "    \n",
    "    # Filter Banks\n",
    "    nfilt = 40\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * np.log10(1 + (sr / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Mel scale\n",
    "    hz_points = (700 * (10 ** (mel_points / 2595) - 1))  # Mel to Hz\n",
    "    bin = np.floor((NFFT + 1) * hz_points / sr).astype(int)\n",
    "    \n",
    "    fbank = np.zeros((nfilt, NFFT // 2 + 1))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = bin[m - 1]   # Left\n",
    "        f_m = bin[m]             # Center\n",
    "        f_m_plus = bin[m + 1]    # Right\n",
    "        \n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    \n",
    "    filter_banks = np.dot(pow_frames, fbank.T)\n",
    "    # Numerical stability\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "    filter_banks = 20 * np.log10(filter_banks)  # Convert to dB\n",
    "    \n",
    "    # MFCCs\n",
    "    mfcc = scipy.fftpack.dct(filter_banks, type=2, axis=1, norm='ortho')[:, :n_mfcc]\n",
    "    # Mean normalization\n",
    "    mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def save_mfcc_to_disk(mfcc, save_path):\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    np.save(save_path, mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Collect sequence lengths\n",
    "# sequence_lengths = []\n",
    "# for file_path in data:\n",
    "#     mfcc = np.load(file_path)\n",
    "#     sequence_lengths.append(mfcc.shape[0])\n",
    "\n",
    "# sequence_lengths = np.array(sequence_lengths)\n",
    "\n",
    "# # Plot histogram\n",
    "# plt.hist(sequence_lengths, bins=50)\n",
    "# plt.xlabel('Sequence Length (Number of Frames)')\n",
    "# plt.ylabel('Number of Sequences')\n",
    "# plt.title('Distribution of MFCC Sequence Lengths')\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate percentiles\n",
    "# print(\"Maximum sequence length:\", np.max(sequence_lengths))\n",
    "# print(\"95th percentile length:\", np.percentile(sequence_lengths, 95))\n",
    "# print(\"90th percentile length:\", np.percentile(sequence_lengths, 90))\n",
    "# print(\"Median sequence length:\", np.median(sequence_lengths))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cry_files = load_audio_files(CRY_FOLDER)\n",
    "notcry_files = load_audio_files(NOTCRY_FOLDER)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for idx, file in enumerate(cry_files):\n",
    "    y, sr = sf.read(file)\n",
    "    y = y.astype(np.float32)\n",
    "    # Normalize the audio signal\n",
    "    y = y / np.max(np.abs(y))\n",
    "    mfcc = compute_mfcc(y, sr, n_mfcc=NUM_MFCC)\n",
    "    save_path = os.path.join(f'{AUDIO_PATH}/mfccs', f'cry_{idx}.npy')\n",
    "    save_mfcc_to_disk(mfcc, save_path)\n",
    "    data.append(save_path)\n",
    "    labels.append(1)\n",
    "    del y, mfcc  # Free up memory\n",
    "\n",
    "for idx, file in enumerate(notcry_files):\n",
    "    y, sr = sf.read(file)\n",
    "    y = y.astype(np.float32)\n",
    "    # Normalize the audio signal\n",
    "    y = y / np.max(np.abs(y))\n",
    "    mfcc = compute_mfcc(y, sr, n_mfcc=NUM_MFCC)\n",
    "    save_path = os.path.join(f'{AUDIO_PATH}/mfccs', f'notcry_{idx}.npy')\n",
    "    save_mfcc_to_disk(mfcc, save_path)\n",
    "    data.append(save_path)\n",
    "    labels.append(0)\n",
    "    del y, mfcc  # Free up memory\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set the fixed maximum sequence length\n",
    "MAX_LENGTH = 499\n",
    "\n",
    "# Improved Data Generator with Fixed Input Sequence Length\n",
    "class OnTheFlyDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self, file_paths, labels, batch_size, num_mfcc, max_length, shuffle=True, augment=False, is_lstm=False\n",
    "    ):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_mfcc = num_mfcc\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.is_lstm = is_lstm\n",
    "        self.indices = np.arange(len(self.file_paths))\n",
    "        self.on_epoch_end()\n",
    "        self.cache = {}  # Optional cache to speed up data loading\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[\n",
    "            index * self.batch_size : min((index + 1) * self.batch_size, len(self.file_paths))\n",
    "        ]\n",
    "        batch_file_paths = [self.file_paths[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "\n",
    "        X, y = self.__data_generation(batch_file_paths, batch_labels)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indices at the end of each epoch\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_file_paths, batch_labels):\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for i, file_path in enumerate(batch_file_paths):\n",
    "            # Load MFCC from .npy file\n",
    "            mfcc = np.load(file_path)\n",
    "\n",
    "            # Augmentation (if any)\n",
    "            if self.augment:\n",
    "                mfcc = self._augment_mfcc(mfcc)\n",
    "\n",
    "            # Pad or truncate the MFCC sequence to max_length\n",
    "            if mfcc.shape[0] < self.max_length:\n",
    "                pad_width = ((0, self.max_length - mfcc.shape[0]), (0, 0))\n",
    "                mfcc = np.pad(mfcc, pad_width, mode='constant')\n",
    "            else:\n",
    "                mfcc = mfcc[: self.max_length, :]\n",
    "\n",
    "            X.append(mfcc)\n",
    "            y.append(batch_labels[i])\n",
    "\n",
    "            # Free up memory\n",
    "            del mfcc\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if self.is_lstm:\n",
    "            # Input shape for LSTM: (batch_size, max_length, num_mfcc)\n",
    "            return X, y\n",
    "        else:\n",
    "            # Input shape for CNN: (batch_size, max_length, num_mfcc, 1)\n",
    "            X = X[..., np.newaxis]  # Add channel dimension\n",
    "            return X, y\n",
    "\n",
    "    def _augment_mfcc(self, mfcc):\n",
    "        # Example augmentation: Add random noise\n",
    "        noise_factor = 0.005\n",
    "        noise = np.random.randn(*mfcc.shape)\n",
    "        mfcc += noise_factor * noise\n",
    "\n",
    "        # Clip to maintain the same range\n",
    "        mfcc = np.clip(mfcc, -1, 1)\n",
    "        return mfcc\n",
    "\n",
    "# Create data generators\n",
    "train_generator = OnTheFlyDataGenerator(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_mfcc=NUM_MFCC,\n",
    "    max_length=MAX_LENGTH,\n",
    "    shuffle=True,\n",
    "    augment=True,\n",
    "    is_lstm=(MODEL == 'lstm'),\n",
    ")\n",
    "\n",
    "val_generator = OnTheFlyDataGenerator(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_mfcc=NUM_MFCC,\n",
    "    max_length=MAX_LENGTH,\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    is_lstm=(MODEL == 'lstm'),\n",
    ")\n",
    "\n",
    "# Define CNN model for hyperparameter tuning\n",
    "def build_cnn_model(hp):\n",
    "    l2_regularizer = tf.keras.regularizers.l2(\n",
    "        hp.Float('l2', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
    "    )\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Conv Block\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            input_shape=(MAX_LENGTH, NUM_MFCC, 1),  # Fixed input shape\n",
    "            kernel_regularizer=l2_regularizer,\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(\n",
    "        Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1))\n",
    "    )\n",
    "\n",
    "    # Second Conv Block\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=hp.Int('filters_2', min_value=64, max_value=256, step=64),\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            kernel_regularizer=l2_regularizer,\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(\n",
    "        Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1))\n",
    "    )\n",
    "\n",
    "    # Third Conv Block\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=hp.Int('filters_3', min_value=128, max_value=512, step=128),\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            kernel_regularizer=l2_regularizer,\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(\n",
    "        Dropout(rate=hp.Float('dropout_3', min_value=0.2, max_value=0.5, step=0.1))\n",
    "    )\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2_regularizer,\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(rate=hp.Float('dropout_fc', min_value=0.3, max_value=0.6, step=0.1))\n",
    "    )\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Float(\n",
    "                'learning_rate', min_value=1e-5, max_value=1e-3, sampling='LOG'\n",
    "            )\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define LSTM model for hyperparameter tuning\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # LSTM Layers with Dropout\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units_1', min_value=64, max_value=256, step=64),\n",
    "            input_shape=(MAX_LENGTH, NUM_MFCC),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            rate=hp.Float('dropout_lstm_1', min_value=0.2, max_value=0.5, step=0.1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units_2', min_value=64, max_value=256, step=64),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            rate=hp.Float('dropout_lstm_2', min_value=0.2, max_value=0.5, step=0.1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units_3', min_value=64, max_value=256, step=64),\n",
    "            return_sequences=False,\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            rate=hp.Float('dropout_lstm_3', min_value=0.2, max_value=0.5, step=0.1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "            activation='relu',\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(rate=hp.Float('dropout_fc', min_value=0.3, max_value=0.6, step=0.1))\n",
    "    )\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Float(\n",
    "                'learning_rate', min_value=1e-5, max_value=1e-3, sampling='LOG'\n",
    "            )\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Training function\n",
    "def train_model(model, model_name):\n",
    "    log_dir = (\n",
    "        \"logs/fit/\"\n",
    "        + model_name\n",
    "        + \"_\"\n",
    "        + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    )\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1, profile_batch='500,520'\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=f'{model_name}_model.keras', monitor='val_loss', save_best_only=True, mode='min'\n",
    "    )\n",
    "    lr_callback = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=25, min_lr=1e-8\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss', patience=5, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[\n",
    "            tensorboard_callback,\n",
    "            checkpoint_callback,\n",
    "            lr_callback,\n",
    "            early_stopping_callback,\n",
    "        ]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning using Keras Tuner\n",
    "if MODEL == 'cnn':\n",
    "    tuner = RandomSearch(\n",
    "        build_cnn_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=20,  # Reduce the number of trials to prevent memory issues\n",
    "        executions_per_trial=1,\n",
    "        directory='hyperparam_tuning',\n",
    "        project_name='cnn_tuning',\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        train_generator,\n",
    "        epochs=15,  # Reduce epochs per trial\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    "    )\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # Build the model with the best hyperparameters and train\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = train_model(model, 'cnn_best')\n",
    "\n",
    "elif MODEL == 'lstm':\n",
    "    tuner = RandomSearch(\n",
    "        build_lstm_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=20,  # Reduce the number of trials\n",
    "        executions_per_trial=1,\n",
    "        directory='hyperparam_tuning',\n",
    "        project_name='lstm_tuning',\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        train_generator,\n",
    "        epochs=15,  # Reduce epochs per trial\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    "    )\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # Build the model with the best hyperparameters and train\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = train_model(model, 'lstm_best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(file_paths, labels, num_mfcc, max_length, is_lstm):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        mfcc = np.load(file_path)\n",
    "        # Pad or truncate the MFCC sequence to max_length\n",
    "        if mfcc.shape[0] < max_length:\n",
    "            pad_width = ((0, max_length - mfcc.shape[0]), (0, 0))\n",
    "            mfcc = np.pad(mfcc, pad_width, mode='constant')\n",
    "        else:\n",
    "            mfcc = mfcc[:max_length, :]\n",
    "\n",
    "        if not is_lstm:\n",
    "            mfcc = mfcc[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "        X.append(mfcc)\n",
    "        y.append(labels[i])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def evaluate_and_save_model(model, model_name, X_val_data, y_true, is_lstm=False):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_val_data)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'Accuracy for {model_name}: {acc:.4f}')\n",
    "    print(f'F1 Score for {model_name}: {f1:.4f}')\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'{model_name}_cry_detection_model.keras')\n",
    "    print(f'{model_name} model saved as {model_name}_cry_detection_model.keras')\n",
    "\n",
    "# Model selection, training, and evaluation\n",
    "if MODEL == 'cnn':\n",
    "    # Load validation data\n",
    "    X_val_data, y_true = load_validation_data(X_val, y_val, NUM_MFCC, MAX_LENGTH, is_lstm=False)\n",
    "    # Evaluate and save the CNN model\n",
    "    evaluate_and_save_model(model, 'cnn', X_val_data, y_true, is_lstm=False)\n",
    "\n",
    "elif MODEL == 'lstm':\n",
    "    # Load validation data\n",
    "    X_val_data, y_true = load_validation_data(X_val, y_val, NUM_MFCC, MAX_LENGTH, is_lstm=True)\n",
    "    # Evaluate and save the LSTM model\n",
    "    evaluate_and_save_model(model, 'lstm', X_val_data, y_true, is_lstm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Create directory for TFLite models\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Allow Select TF Ops for both CNN and LSTM models if necessary\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "# For LSTM models, disable experimental lowering of tensor list ops\n",
    "if MODEL == 'lstm':\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "tflite_model_file = tflite_models_dir / \"cry_detection_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "# Apply optimizations and convert again\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_quant_file = tflite_models_dir / \"cry_detection_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
    "\n",
    "print(\"TFLite conversion successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.fftpack\n",
    "\n",
    "# Initialize the TFLite interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_models/cry_detection_model_quant.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def preprocess_audio(file_path, num_mfcc=NUM_MFCC, is_lstm=False):\n",
    "    y, sr = sf.read(file_path)\n",
    "    y = y.astype(np.float32)\n",
    "    # Normalize the audio signal\n",
    "    y = y / np.max(np.abs(y))\n",
    "    # Compute MFCCs\n",
    "    mfcc = compute_mfcc(y, sr, n_mfcc=num_mfcc)\n",
    "    # Add channel dimension for CNN models\n",
    "    if not is_lstm:\n",
    "        mfcc = mfcc[..., np.newaxis]\n",
    "    return mfcc\n",
    "\n",
    "def predict(file_path, num_mfcc=NUM_MFCC, is_lstm=False):\n",
    "    input_data = preprocess_audio(file_path, num_mfcc, is_lstm)\n",
    "    \n",
    "    # Adjust input shape for LSTM and CNN\n",
    "    if is_lstm:\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(np.float32)  # Shape: (1, time_steps, num_mfcc)\n",
    "    else:\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(np.float32)  # Shape: (1, time_steps, num_mfcc, 1)\n",
    "    \n",
    "    # Set the tensor to point to the input data for inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get the output prediction\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "def process_folder(folder_path, num_mfcc=NUM_MFCC, is_lstm=False):\n",
    "    correct_predictions = 0\n",
    "    total_files = 0\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            prediction = predict(file_path, num_mfcc, is_lstm)\n",
    "            prediction_label = 'Cry' if prediction > 0.5 else 'Not Cry'\n",
    "            results.append((file_name, prediction_label))\n",
    "            ground_truth = 'Cry' if '_cry.wav' in file_name else 'Not Cry'\n",
    "\n",
    "            if prediction_label == ground_truth:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            total_files += 1\n",
    "\n",
    "    accuracy = (correct_predictions / total_files) * 100 if total_files > 0 else 0\n",
    "\n",
    "    return results, accuracy\n",
    "\n",
    "\n",
    "folder_path = '{0}/Test_augmented'.format(AUDIO_PATH)\n",
    "if MODEL == 'lstm': \n",
    "    is_lstm_model = True  \n",
    "else: \n",
    "    is_lstm_model = False\n",
    "predictions, accuracy = process_folder(folder_path, num_mfcc=NUM_MFCC, is_lstm=is_lstm_model)\n",
    "\n",
    "for file_name, prediction_label in predictions:\n",
    "    print(f\"File: {file_name}, Prediction: {prediction_label}\")\n",
    "\n",
    "print(f\"Prediction Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.fftpack\n",
    "import ctypes\n",
    "\n",
    "# Load the TFLite C library\n",
    "lib = ctypes.cdll.LoadLibrary('/home/garfield/repos/cry-detection/libtensorflowlite_c_2_14_1_amd64.so')\n",
    "\n",
    "# Define types for the C API functions\n",
    "lib.TfLiteModelCreate.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "lib.TfLiteInterpreterCreate.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "lib.TfLiteInterpreterOptionsCreate.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "lib.TfLiteInterpreterOptionsSetNumThreads.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_int]\n",
    "lib.TfLiteInterpreterOptionsDelete.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "lib.TfLiteInterpreterDelete.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "lib.TfLiteModelDelete.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "lib.TfLiteInterpreterGetInputTensor.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "lib.TfLiteInterpreterGetOutputTensor.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "lib.TfLiteTensorCopyFromBuffer.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_void_p, ctypes.c_size_t]\n",
    "lib.TfLiteTensorCopyToBuffer.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_void_p, ctypes.c_size_t]\n",
    "lib.TfLiteInterpreterInvoke.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "lib.TfLiteInterpreterAllocateTensors.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "lib.TfLiteInterpreterGetInputTensor.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_int]\n",
    "lib.TfLiteInterpreterGetOutputTensor.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_int]\n",
    "\n",
    "model_path = b\"tflite_models/cry_detection_model_quant.tflite\"\n",
    "with open(model_path, 'rb') as f:\n",
    "    model_data = f.read()\n",
    "\n",
    "model = lib.TfLiteModelCreate(ctypes.c_char_p(model_data), ctypes.c_size_t(len(model_data)))\n",
    "\n",
    "# Create interpreter options and set number of threads\n",
    "options = lib.TfLiteInterpreterOptionsCreate()\n",
    "lib.TfLiteInterpreterOptionsSetNumThreads(options, 2)\n",
    "\n",
    "# Create the interpreter with the custom options\n",
    "interpreter = lib.TfLiteInterpreterCreate(model, options)\n",
    "\n",
    "# Allocate tensors\n",
    "status = lib.TfLiteInterpreterAllocateTensors(interpreter)\n",
    "\n",
    "# Get input and output tensor pointers\n",
    "input_tensor = lib.TfLiteInterpreterGetInputTensor(interpreter, 0)\n",
    "output_tensor = lib.TfLiteInterpreterGetOutputTensor(interpreter, 0)\n",
    "\n",
    "def compute_mfcc(y, sr, n_mfcc=NUM_MFCC):\n",
    "    # Pre-emphasis filter\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_signal = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
    "    \n",
    "    # Frame parameters\n",
    "    frame_size = 0.025  # 25 ms\n",
    "    frame_stride = 0.010  # 10 ms\n",
    "    frame_length, frame_step = int(round(frame_size * sr)), int(round(frame_stride * sr))\n",
    "    signal_length = len(emphasized_signal)\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))\n",
    "    \n",
    "    # Padding\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(emphasized_signal, z)\n",
    "    \n",
    "    # Framing\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    # Windowing with Hamming window\n",
    "    frames *= np.hamming(frame_length)\n",
    "    \n",
    "    # Fourier Transform and Power Spectrum\n",
    "    NFFT = 512\n",
    "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
    "    pow_frames = ((1.0 / NFFT) * (mag_frames ** 2))\n",
    "    \n",
    "    # Filter Banks\n",
    "    nfilt = 40\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * np.log10(1 + (sr / 2) / 700))\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)\n",
    "    hz_points = (700 * (10 ** (mel_points / 2595) - 1))\n",
    "    bin = np.floor((NFFT + 1) * hz_points / sr).astype(int)\n",
    "    \n",
    "    fbank = np.zeros((nfilt, NFFT // 2 + 1))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = bin[m - 1]\n",
    "        f_m = bin[m]\n",
    "        f_m_plus = bin[m + 1]\n",
    "        \n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    \n",
    "    filter_banks = np.dot(pow_frames, fbank.T)\n",
    "    # Numerical stability\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "    filter_banks = 20 * np.log10(filter_banks)\n",
    "    \n",
    "    # MFCCs\n",
    "    mfcc = scipy.fftpack.dct(filter_banks, type=2, axis=1, norm='ortho')[:, :n_mfcc]\n",
    "    # Mean normalization\n",
    "    mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def preprocess_audio(file_path, num_mfcc=NUM_MFCC, max_length=99, is_lstm=False):\n",
    "    y, sr = sf.read(file_path)\n",
    "    y = y.astype(np.float32)\n",
    "    y = y / np.max(np.abs(y))\n",
    "    mfcc = compute_mfcc(y, sr, n_mfcc=num_mfcc)\n",
    "    \n",
    "    # Pad or truncate to fixed length\n",
    "    if mfcc.shape[0] < max_length:\n",
    "        pad_width = ((0, max_length - mfcc.shape[0]), (0, 0))\n",
    "        mfcc = np.pad(mfcc, pad_width, mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length, :]\n",
    "    \n",
    "    if not is_lstm:\n",
    "        mfcc = mfcc[..., np.newaxis]  # Add channel dimension for CNN\n",
    "    return mfcc\n",
    "\n",
    "def predict(file_path, num_mfcc=NUM_MFCC, max_length=99, is_lstm=False):\n",
    "    input_data = preprocess_audio(file_path, num_mfcc, max_length, is_lstm)\n",
    "    \n",
    "    # Adjust input shape for LSTM and CNN\n",
    "    if is_lstm:\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(np.float32)  # Shape: (1, time_steps, num_mfcc)\n",
    "    else:\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(np.float32)  # Shape: (1, time_steps, num_mfcc, 1)\n",
    "    \n",
    "    # Set the tensor to point to the input data to be inferred\n",
    "    lib.TfLiteTensorCopyFromBuffer(\n",
    "        input_tensor,\n",
    "        input_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "        ctypes.c_size_t(input_data.nbytes)\n",
    "    )\n",
    "    \n",
    "    # Run inference\n",
    "    lib.TfLiteInterpreterInvoke(interpreter)\n",
    "    \n",
    "    # Extract output data\n",
    "    output_size = 1\n",
    "    output_data = np.empty(output_size, dtype=np.float32)\n",
    "    lib.TfLiteTensorCopyToBuffer(\n",
    "        output_tensor,\n",
    "        output_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "        ctypes.c_size_t(output_data.nbytes)\n",
    "    )\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "def process_folder(folder_path, num_mfcc=NUM_MFCC, max_length=99, is_lstm=False):\n",
    "    correct_predictions = 0\n",
    "    total_files = 0\n",
    "    results = []\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            prediction = predict(file_path, num_mfcc, max_length, is_lstm)\n",
    "            prediction_label = 'Cry' if prediction > 0.5 else 'Not Cry'\n",
    "            results.append((file_name, prediction_label))\n",
    "            ground_truth = 'Cry' if '_cry.wav' in file_name else 'Not Cry'\n",
    "\n",
    "            if prediction_label == ground_truth:\n",
    "                correct_predictions += 1\n",
    "                if prediction_label == 'Cry':\n",
    "                    true_positives += 1\n",
    "            else:\n",
    "                if prediction_label == 'Cry':\n",
    "                    false_positives += 1\n",
    "                elif prediction_label == 'Not Cry' and ground_truth == 'Cry':\n",
    "                    false_negatives += 1\n",
    "\n",
    "            total_files += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (correct_predictions / total_files) * 100 if total_files > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    false_negative_percentage = (false_negatives / (false_negatives + true_positives)) * 100 if (false_negatives + true_positives) > 0 else 0\n",
    "\n",
    "    return results, accuracy, f1, false_negative_percentage\n",
    "\n",
    "# Specify the folder containing test audio files\n",
    "folder_path = '{0}/Test_augmented'.format(AUDIO_PATH)\n",
    "if MODEL == 'lstm':\n",
    "    is_lstm_model = True\n",
    "else:\n",
    "    is_lstm_model = False\n",
    "\n",
    "# Set max_length based on training parameters (adjust as necessary)\n",
    "max_length = 499  # This should match the max_length used during model training\n",
    "\n",
    "predictions, accuracy, f1_score, false_negative_percentage = process_folder(\n",
    "    folder_path,\n",
    "    num_mfcc=NUM_MFCC,\n",
    "    max_length=max_length,\n",
    "    is_lstm=is_lstm_model\n",
    ")\n",
    "\n",
    "for file_name, prediction_label in predictions:\n",
    "    print(f\"File: {file_name}, Prediction: {prediction_label}\")\n",
    "\n",
    "print(f\"Prediction Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "print(f\"False Negative Percentage: {false_negative_percentage:.2f}%\")\n",
    "\n",
    "# Clean up resources\n",
    "lib.TfLiteInterpreterDelete(interpreter)\n",
    "lib.TfLiteInterpreterOptionsDelete(options)\n",
    "lib.TfLiteModelDelete(model)\n",
    "\n",
    "print(\"All operations completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 3 Complete [00h 02m 28s]\n",
    "# val_accuracy: 0.9020833373069763\n",
    "\n",
    "# Best val_accuracy So Far: 0.9354166388511658\n",
    "# Total elapsed time: 00h 07m 32s\n",
    "\n",
    "# Search: Running Trial #4\n",
    "\n",
    "# Value             |Best Value So Far |Hyperparameter\n",
    "# 0.0013197         |4.6117e-05        |l2\n",
    "# 64                |128               |filters_1\n",
    "# 0.3               |0.2               |dropout_1\n",
    "# 128               |256               |filters_2\n",
    "# 0.2               |0.2               |dropout_2\n",
    "# 384               |128               |filters_3\n",
    "# 0.4               |0.4               |dropout_3\n",
    "# 256               |256               |dense_units\n",
    "# 0.4               |0.3               |dropout_fc\n",
    "# 0.0049677         |2.53e-05          |learning_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
