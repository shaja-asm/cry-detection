{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaja-asm/cry-detection/blob/main/cry_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlurjUaxlSjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb79562-a69d-4657-fa10-d650887723c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6UHLeMo7xgI",
        "outputId": "d687e5ec-6022-4f4b-f7fe-bfc5e98675a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CRY_PATH = '/content/drive/MyDrive/CryCorpusFinal/cry'\n",
        "NOCRY_PATH = '/content/drive/MyDrive/CryCorpusFinal/notcry'\n",
        "Fs = 22050\n",
        "\n",
        "def load_audio_files(path):\n",
        "    files = []\n",
        "    for file_name in os.listdir(path):\n",
        "        if file_name.endswith('.wav'):\n",
        "            files.append(os.path.join(path, file_name))\n",
        "    return files\n",
        "\n",
        "cry_files = load_audio_files(CRY_PATH)\n",
        "nocry_files = load_audio_files(NOCRY_PATH)\n",
        "\n",
        "print(f'Loaded {len(cry_files)} cry files and {len(nocry_files)} nocry files.')\n"
      ],
      "metadata": {
        "id": "X9aaRCS8ltu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8211b84-15a0-4f6e-cb80-dfd136bad17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 972 cry files and 1066 nocry files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_audio(y, segment_length=0.093, fs=22050):\n",
        "    segment_samples = int(segment_length * fs)\n",
        "    segments = []\n",
        "    for start in range(0, len(y) - segment_samples + 1, segment_samples):\n",
        "        segment = y[start:start + segment_samples]\n",
        "        segments.append(segment)\n",
        "    return np.array(segments)\n",
        "\n",
        "def extract_mfccs(file_paths, fs=22050, n_mfcc=38):\n",
        "    mfccs = []\n",
        "    for file_path in file_paths:\n",
        "        y, _ = librosa.load(file_path, sr=fs)\n",
        "        segments = segment_audio(y, fs=fs)\n",
        "        for segment in segments:\n",
        "            mfcc = librosa.feature.mfcc(y=segment, sr=fs, n_mfcc=n_mfcc).T\n",
        "            mfccs.append(mfcc)\n",
        "    return np.vstack(mfccs)\n",
        "\n",
        "# Take a sample of cry and nocry files to fit the PCA\n",
        "sample_cry_files = cry_files[:50]\n",
        "sample_nocry_files = nocry_files[:50]\n",
        "\n",
        "# Extract MFCCs from the sample files\n",
        "mfcc_sample = extract_mfccs(sample_cry_files + sample_nocry_files)\n",
        "\n",
        "# Fit PCA on the extracted MFCCs\n",
        "pca = PCA(n_components=8)\n",
        "pca.fit(mfcc_sample)\n",
        "\n",
        "print(\"PCA model fitted on sample MFCC data\")\n",
        "\n",
        "# Test\n",
        "test_file = cry_files[0]\n",
        "y, _ = librosa.load(test_file, sr=Fs)\n",
        "segments = segment_audio(y)\n",
        "print(f'Segments: {segments.shape[0]}')\n"
      ],
      "metadata": {
        "id": "PY8RsBHRl-J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a93b03f-1195-4599-d5ac-875561785f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA model fitted on sample MFCC data\n",
            "Segments: 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(segment, fs=22050):\n",
        "    # MFCCs\n",
        "    # mfcc = librosa.feature.mfcc(y=segment, sr=fs, n_mfcc=38)\n",
        "    # mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc = librosa.feature.mfcc(y=segment, sr=fs, n_mfcc=38)\n",
        "    if pca is not None:\n",
        "      mfcc = pca.transform(mfcc.T).T  # Transform the MFCCs using PCA\n",
        "    mfcc_flat = mfcc.flatten()  # Flatten the PCA-transformed MFCCs\n",
        "\n",
        "    # Short-time energy (STE)\n",
        "    ste = np.sum(segment ** 2)\n",
        "\n",
        "    # Zero-crossing rate (ZCR)\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(segment))\n",
        "\n",
        "    # Pitch median value within a segment\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=segment, sr=fs)\n",
        "    pitch_median = np.median(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
        "\n",
        "    # Run-length of pitch (number of consecutive voiced frames where pitch was detected)\n",
        "    voiced_frames = pitches > 0\n",
        "    run_length = np.sum(np.diff(voiced_frames.astype(int)) == -1)\n",
        "\n",
        "    # Spectral rolloff point\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=segment, sr=fs))\n",
        "\n",
        "    # First formant (approximated using linear predictive coding)\n",
        "    lpc = librosa.lpc(segment, order=2)\n",
        "    roots = np.roots(lpc)\n",
        "    roots = roots[np.imag(roots) >= 0]\n",
        "    angles = np.arctan2(np.imag(roots), np.real(roots))\n",
        "    frequencies = angles * (fs / (2 * np.pi))\n",
        "    frequencies = np.sort(frequencies)\n",
        "    first_formant = frequencies[0] if len(frequencies) > 0 else 0\n",
        "\n",
        "    # Energy ratio(Ratio (in dB) between the spectral energy in the frequency bands [0, 3.5]kHz and [3.5, 22.5]kHz)\n",
        "    energy = np.abs(librosa.stft(segment))\n",
        "    energy_low = np.sum(energy[(0 <= librosa.fft_frequencies(sr=fs)) & (librosa.fft_frequencies(sr=fs) <= 3500)])\n",
        "    energy_high = np.sum(energy[(3500 < librosa.fft_frequencies(sr=fs)) & (librosa.fft_frequencies(sr=fs) <= 22500)])\n",
        "    energy_ratio = 10 * np.log10(energy_low / energy_high) if energy_high > 0 else 0\n",
        "\n",
        "    return np.hstack([mfcc_flat, ste, zcr, pitch_median, run_length, first_formant, energy_ratio, spectral_rolloff])\n",
        "\n",
        "\n",
        "#Test\n",
        "features = extract_features(segments[0])\n",
        "print(f'Extracted features shape: {features.shape}')"
      ],
      "metadata": {
        "id": "XR7H0YgOmWX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72689d6f-dc76-490f-e120-765d7adfc37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features shape: (47,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files(file_paths, label):\n",
        "    data = []\n",
        "    for file_path in file_paths:\n",
        "        y, _ = librosa.load(file_path, sr=Fs)\n",
        "        segments = segment_audio(y)\n",
        "        for segment in segments:\n",
        "            features = extract_features(segment)\n",
        "            data.append(np.hstack([features, label]))\n",
        "    return np.array(data)\n",
        "\n",
        "cry_data = process_files(cry_files, 1)\n",
        "nocry_data = process_files(nocry_files, 0)\n",
        "data = np.vstack([cry_data, nocry_data])\n",
        "print(f'Total dataset size: {data.shape}')"
      ],
      "metadata": {
        "id": "Zy_q-mlGmqjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444c16fa-175d-4df3-e79b-ac6e03dbf516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: (108014, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f'Train set: {X_train.shape}, Test set: {X_test.shape}')\n",
        "\n",
        "# Create mask for NaN values\n",
        "train_mask = ~np.isnan(X_train).any(axis=1)\n",
        "test_mask = ~np.isnan(X_test).any(axis=1)\n",
        "\n",
        "# Apply mask to both X and y\n",
        "X_train = X_train[train_mask]\n",
        "y_train = y_train[train_mask]\n",
        "\n",
        "X_test = X_test[test_mask]\n",
        "y_test = y_test[test_mask]\n",
        "\n",
        "print(f'Train set after NaN removal: {X_train.shape}, Test set after NaN removal: {X_test.shape}')\n",
        "\n",
        "#Normalize\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the data for the model input\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n"
      ],
      "metadata": {
        "id": "E3xsyvI_m2dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcba2863-5bf8-4e56-bc50-994af5ffa600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (86411, 47), Test set: (21603, 47)\n",
            "Train set after NaN removal: (86411, 47), Test set after NaN removal: (21603, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer_model(input_shape, learning_rate=0.0001):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Add Transformer Encoder Layer\n",
        "    attention_output = MultiHeadAttention(num_heads=4, key_dim=64)(inputs, inputs)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "    # Add Feed Forward Network\n",
        "    ff_output = Dense(64, activation='relu')(attention_output)\n",
        "    ff_output = Dense(input_shape[1], activation='relu')(ff_output)\n",
        "    ff_output = LayerNormalization(epsilon=1e-6)(ff_output)\n",
        "\n",
        "    # Pooling\n",
        "    x = GlobalAveragePooling1D()(ff_output)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "model = build_transformer_model(input_shape, learning_rate=0.0001)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "A8cceY1bm3ZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225fd851-ea4f-4d7f-fcf4-178449fa039e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 47, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 47, 1)                1793      ['input_2[0][0]',             \n",
            " ltiHeadAttention)                                                   'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 47, 1)                2         ['multi_head_attention_1[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 47, 64)               128       ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 47, 1)                65        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 47, 1)                2         ['dense_4[0][0]']             \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 1)                    0         ['layer_normalization_3[0][0]'\n",
            "  (GlobalAveragePooling1D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1)                    2         ['global_average_pooling1d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1992 (7.78 KB)\n",
            "Trainable params: 1992 (7.78 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train[..., np.newaxis], y_train,\n",
        "    validation_data=(X_test[..., np.newaxis], y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7p2p08-_m5Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test[..., np.newaxis], y_test)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "g01Z2jRqm7b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cry_detection_model.h5')"
      ],
      "metadata": {
        "id": "KFGZW93NqmjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('cry_detection_model.h5')\n",
        "\n",
        "TEST_PATH = 'CryCorpusFinal/Test'\n",
        "Fs = 22050\n",
        "\n",
        "def load_audio_files(path):\n",
        "    files = []\n",
        "    for file_name in os.listdir(path):\n",
        "        if file_name.endswith('.wav'):\n",
        "            files.append(os.path.join(path, file_name))\n",
        "    return files\n",
        "\n",
        "test_files = load_audio_files(TEST_PATH)\n",
        "print(f'Loaded {len(test_files)} test files.')\n",
        "\n",
        "def segment_audio(y, segment_length=0.093, overlap=0.5, fs=22050):\n",
        "    segment_samples = int(segment_length * fs)\n",
        "    step_samples = int(segment_samples * (1 - overlap))\n",
        "    segments = []\n",
        "    for start in range(0, len(y) - segment_samples + 1, step_samples):\n",
        "        segment = y[start:start + segment_samples]\n",
        "        segments.append(segment)\n",
        "    return np.array(segments)\n",
        "\n",
        "def extract_features(segment, fs=22050):\n",
        "    mfcc = librosa.feature.mfcc(y=segment, sr=fs, n_mfcc=38).flatten()\n",
        "    ste = np.sum(segment ** 2)\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(segment))\n",
        "\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=segment, sr=fs)\n",
        "    pitch_median = np.median(pitches[pitches > 0])\n",
        "\n",
        "    harmonicity = np.sum(magnitudes ** 2) / np.sum(magnitudes)\n",
        "    hapr = harmonicity / np.mean(magnitudes)\n",
        "\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=segment, sr=fs))\n",
        "\n",
        "    return np.hstack([mfcc, ste, zcr, pitch_median, harmonicity, hapr, spectral_rolloff])\n",
        "\n",
        "def predict_cry(file_path, model, fs=22050):\n",
        "    y, _ = librosa.load(file_path, sr=fs)\n",
        "    segments = segment_audio(y)\n",
        "    predictions = []\n",
        "    for segment in segments:\n",
        "        features = extract_features(segment)\n",
        "        features = features.reshape(1, -1, 1)  # Reshape for the model input\n",
        "        prediction = model.predict(features)\n",
        "        predictions.append(prediction)\n",
        "    return np.mean(predictions)  # Return the average prediction\n",
        "\n",
        "# Predict on the test files\n",
        "results = []\n",
        "for file_path in test_files:\n",
        "    prediction = predict_cry(file_path, model)\n",
        "    label = 'cry' if prediction > 0.5 else 'nocry'\n",
        "    results.append((file_path, prediction, label))\n",
        "    print(f'File: {file_path}, Prediction: {prediction:.4f}, Label: {label}')\n"
      ],
      "metadata": {
        "id": "iLCAzGErqy7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}